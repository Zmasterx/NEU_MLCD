{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":62256,"databundleVersionId":7143660,"sourceType":"competition"},{"sourceId":3043853,"sourceType":"datasetVersion","datasetId":1864103},{"sourceId":4309106,"sourceType":"datasetVersion","datasetId":2538358}],"dockerImageVersionId":30171,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Retinal Vessel\n\nThe retinal vessel segmentation is a binary image segmentation. Currently there are 4 well used dataset are available for this task. [HERE](https://www.kaggle.com/ipythonx/retinal-vessel-segmentation) is the dataset all together. \n\n```\nCHASE DB1\nDRIVE\nHRF\nSTARE\n```\n\nIn this starter notebook, we will explore all of them but additionally we will run a simple segmentation model on **DRIVE** dataset only. Rest of the datasets are pretty same format and should be easy to run.","metadata":{"execution":{"iopub.status.busy":"2022-03-10T09:38:39.933468Z","iopub.execute_input":"2022-03-10T09:38:39.933797Z","iopub.status.idle":"2022-03-10T09:38:52.484879Z","shell.execute_reply.started":"2022-03-10T09:38:39.933712Z","shell.execute_reply":"2022-03-10T09:38:52.4838Z"}}},{"cell_type":"code","source":"!pip install -U -q segmentation-models --user\n\nfrom PIL import Image\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n\nimport segmentation_models as sm\nimport matplotlib.pyplot as plt \nimport tensorflow_io as tfio\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\n\nroot = '../input/retinal-vessel-segmentation'\nexts = ('jpg', 'JPG', 'png', 'PNG', 'tif', 'gif', 'ppm')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-24T07:02:35.368494Z","iopub.execute_input":"2023-11-24T07:02:35.369294Z","iopub.status.idle":"2023-11-24T07:02:37.439255Z","shell.execute_reply.started":"2023-11-24T07:02:35.369239Z","shell.execute_reply":"2023-11-24T07:02:37.438255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DRIVE\n\nThe dataset comes with pair of input retina image and target mask. Among all retina image, we will only use this dataset for a quick baseline. However, rest of the dataset can be replaces easily on this pipeline.\n","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing Images","metadata":{}},{"cell_type":"code","source":"def restrict_normalized(imgs):\n    imgs_normalized = np.empty(imgs.shape)\n    imgs_std = np.std(imgs)\n    imgs_mean = np.mean(imgs)\n    imgs_normalized = (imgs-imgs_mean)/imgs_std\n    imgs_normalized = ((imgs_normalized - np.min(imgs_normalized)) / (np.max(imgs_normalized)-np.min(imgs_normalized)))*255\n    return imgs_normalized\n\n# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n#adaptive histogram equalization is used. In this, image is divided into small blocks called \"tiles\" (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual. So in a small area, histogram would confine to a small region (unless there is noise). If noise is there, it will be amplified. To avoid this, contrast limiting is applied. If any histogram bin is above the specified contrast limit (by default 40 in OpenCV), those pixels are clipped and distributed uniformly to other bins before applying histogram equalization. After equalization, to remove artifacts in tile borders, bilinear interpolation is applied\ndef clahe_equalized(imgs):\n  clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(16,16))\n  imgs_equalized = np.empty(imgs.shape)\n  imgs_equalized = clahe.apply(np.array(imgs, dtype = np.uint8))\n  return imgs_equalized\n\ndef normalized(imgs):\n  imgs_normalized =np.empty(imgs.shape)\n  imgs_normalized =cv2.equalizeHist(imgs)\n  return imgs_normalized\n\ndef adjust_gamma(imgs, gamma=1.0):\n  invGamma = 1.0 / gamma\n  table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n  # apply gamma correction using the lookup table\n  new_imgs = np.empty(imgs.shape)\n  new_imgs = cv2.LUT(np.array(imgs, dtype = np.uint8), table)\n  return new_imgs\n\ndef expand(image):\n  arr = np.zeros(image.shape + (3,))\n  arr[:,:,0] = image[:,:]\n  arr[:,:,1] = image[:,:]\n  arr[:,:,2] = image[:,:]\n  return arr\n\ndef preprocess(image):\n  image=restrict_normalized(image)\n  image=clahe_equalized(image)\n  image=adjust_gamma(image,1.2)\n  image=image/255.0\n  image=expand(image)\n  return image","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.441368Z","iopub.execute_input":"2023-11-24T07:02:37.441633Z","iopub.status.idle":"2023-11-24T07:02:37.456163Z","shell.execute_reply.started":"2023-11-24T07:02:37.441599Z","shell.execute_reply":"2023-11-24T07:02:37.455352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nfrom PIL import Image\n\nprocessed_path = './Processed_images_Drive'\n\nos.mkdir(path=processed_path)\ndirectory = '../input/retinal-vessel-segmentation/DRIVE/training/images/'\nfor fname in os.listdir(directory):\n    image = plt.imread(directory + fname)\n    image = image[:,:,1]\n    processed_img = preprocess(image)\n    print(processed_img.shape)\n    processed_img = Image.fromarray((processed_img * 255).astype(np.uint8))\n    processed_img.save(processed_path + '/' + fname)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.457422Z","iopub.execute_input":"2023-11-24T07:02:37.457724Z","iopub.status.idle":"2023-11-24T07:02:37.507228Z","shell.execute_reply.started":"2023-11-24T07:02:37.457688Z","shell.execute_reply":"2023-11-24T07:02:37.504048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data = os.path.join('./', 'Processed_images_Drive')\nimages = sorted(\n    [\n        os.path.join(input_data, fname)\n        for fname in os.listdir('./Processed_images_Drive')\n        if fname.endswith(exts) and not fname.startswith(\".\")\n    ]\n)\n\n\ntarget_data = os.path.join(root, 'DRIVE/training/1st_manual')\nmasks = sorted(\n    [\n        os.path.join(target_data, fname)\n        for fname in os.listdir(target_data)\n        if fname.endswith(exts) and not fname.startswith(\".\")\n    ]\n)\n\nprint(\"Number of samples:\", len(images), len(masks))\nfor input_path, target_path in zip(images[:10], masks[:10]):\n    print(input_path[-31:], \"|\", target_path[-34:])","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.507988Z","iopub.status.idle":"2023-11-24T07:02:37.508283Z","shell.execute_reply.started":"2023-11-24T07:02:37.508126Z","shell.execute_reply":"2023-11-24T07:02:37.508141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagesss = cv2.imread('./Processed_images_Drive/22_training.tif')\nprint(imagesss.shape)\nplt.imshow(imagesss)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.509279Z","iopub.status.idle":"2023-11-24T07:02:37.509698Z","shell.execute_reply.started":"2023-11-24T07:02:37.509464Z","shell.execute_reply":"2023-11-24T07:02:37.509487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 512\nBATCH_SIZE = 12\n\ndef read_files(image_path, mask=False):\n    image = tf.io.read_file(image_path)\n    if mask:\n        image = tf.io.decode_gif(image) # out: (1, h, w, 3)\n        image = tf.squeeze(image) # out: (h, w, 3)\n        image = tf.image.rgb_to_grayscale(image) # out: (h, w, 1)\n        image = tf.divide(image, 128)\n        image.set_shape([None, None, 1])\n        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n        image = tf.cast(image, tf.int32)\n    else:\n        image = tfio.experimental.image.decode_tiff(image) # out: (h, w, 4)\n        image = image[:,:,:3] # out: (h, w, 3)\n        image.set_shape([None, None, 3])\n        image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n        image = image / 255.\n    return image\n\ndef load_data(image_list, mask_list):\n    image = read_files(image_list)\n    mask  = read_files(mask_list, mask=True)\n    return image, mask\n\ndef data_generator(image_list, mask_list):\n    dataset = tf.data.Dataset.from_tensor_slices((image_list, mask_list))\n    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset1 = dataset.take(15)\n    dataset2 = dataset.skip(15)\n    dataset1 = dataset1.batch(BATCH_SIZE, drop_remainder=False)\n    dataset2 = dataset2.batch(2, drop_remainder=False)\n    return dataset1, dataset2\n\ntrain_dataset, valid_dataset = data_generator(images, masks)\ntrain_dataset, valid_dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.510551Z","iopub.status.idle":"2023-11-24T07:02:37.510966Z","shell.execute_reply.started":"2023-11-24T07:02:37.510735Z","shell.execute_reply":"2023-11-24T07:02:37.510761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images) \n    plt.figure(figsize=(20, 20))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image, cmap='gray')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.512077Z","iopub.status.idle":"2023-11-24T07:02:37.512419Z","shell.execute_reply.started":"2023-11-24T07:02:37.512255Z","shell.execute_reply":"2023-11-24T07:02:37.512272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, mask = next(iter(train_dataset.take(1))) \nprint(image.shape, mask.shape)\n\nfor (img, msk) in zip(image[:5], mask[:5]):\n    print(mask.numpy().min(), mask.numpy().max())\n    print(np.unique(mask.numpy()))\n    visualize(\n        image=img.numpy(),\n        gt_mask=msk.numpy(),\n    )","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.513317Z","iopub.status.idle":"2023-11-24T07:02:37.513775Z","shell.execute_reply.started":"2023-11-24T07:02:37.513517Z","shell.execute_reply":"2023-11-24T07:02:37.513564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras \n\n# Free up RAM in case the model definition cells were run multiple times\nkeras.backend.clear_session()\nBACKBONE   = 'vgg19'\nn_classes  = 1 \nactivation = 'sigmoid' \nmodel = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\nmodel.summary(line_length=110)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.515404Z","iopub.status.idle":"2023-11-24T07:02:37.515742Z","shell.execute_reply.started":"2023-11-24T07:02:37.515563Z","shell.execute_reply":"2023-11-24T07:02:37.515588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Callback : Monitoring Training Progress","metadata":{}},{"cell_type":"code","source":"class DisplayCallback(keras.callbacks.Callback):\n    def __init__(self, dataset, epoch_interval=5):\n        self.dataset = dataset\n        self.epoch_interval = epoch_interval\n    \n    def display(self, display_list, extra_title=''):\n        plt.figure(figsize=(15, 15))\n        title = ['Input Image', 'True Mask', 'Predicted Mask']\n\n        if len(display_list) > len(title):\n            title.append(extra_title)\n\n        for i in range(len(display_list)):\n            plt.subplot(1, len(display_list), i+1)\n            plt.title(title[i])\n            plt.imshow(display_list[i], cmap='gray')\n            plt.axis('off')\n        plt.show()\n        \n    def create_mask(self, pred_mask):\n        pred_mask = (pred_mask > 0.5).astype(\"int32\")\n        return pred_mask[0]\n    \n    def show_predictions(self, dataset, num=1):\n        for image, mask in dataset.take(num):\n            pred_mask = model.predict(image)\n            self.display([image[0], mask[0], self.create_mask(pred_mask)])\n        \n    def on_epoch_end(self, epoch, logs=None):\n        if epoch and epoch % self.epoch_interval == 0:\n            self.show_predictions(self.dataset)\n            print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.516844Z","iopub.status.idle":"2023-11-24T07:02:37.517157Z","shell.execute_reply.started":"2023-11-24T07:02:37.51698Z","shell.execute_reply":"2023-11-24T07:02:37.517004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compile and Fit","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n\n# define optomizer\noptim = keras.optimizers.Adam(0.0003)\nbce   = keras.losses.BinaryCrossentropy()\nmetrics = [\"accuracy\"]\n\n# compile keras model with defined optimozer, loss and metrics\nmodel.compile(optim, bce, metrics)\n\nfilepath = './unet_backbone_vgg19.h5'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\nrlrop = ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.6, min_lr=1e-7, verbose=1)\n\nhistory = model.fit(\n    train_dataset,\n    epochs=400,\n    callbacks=[DisplayCallback(train_dataset), checkpoint, rlrop],\n    validation_data=valid_dataset\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.518552Z","iopub.status.idle":"2023-11-24T07:02:37.518848Z","shell.execute_reply.started":"2023-11-24T07:02:37.518692Z","shell.execute_reply":"2023-11-24T07:02:37.518707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the loss\nplt.plot(history.history['loss'], label='training loss')\nplt.plot(history.history['val_loss'], label='validation loss')\nplt.legend()\nplt.show()\n#plt.savefig('LossVal_loss')\n\n# plot the accuracy\nplt.plot(history.history['accuracy'], label='training accuracy')\nplt.plot(history.history['val_accuracy'], label='validation accuracy')\nplt.legend()\nplt.show()\n#plt.savefig('AccVal_acc')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.519898Z","iopub.status.idle":"2023-11-24T07:02:37.520211Z","shell.execute_reply.started":"2023-11-24T07:02:37.520032Z","shell.execute_reply":"2023-11-24T07:02:37.520056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.models.save_model(model, './unet_backbone2_vgg19.h5')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.521302Z","iopub.status.idle":"2023-11-24T07:02:37.521643Z","shell.execute_reply.started":"2023-11-24T07:02:37.52144Z","shell.execute_reply":"2023-11-24T07:02:37.521462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating Functions","metadata":{}},{"cell_type":"code","source":"def my_dice(target, prediction):\n intersection = np.logical_and(target, prediction)\n union = np.logical_or(target, prediction)\n dice = (2*np.sum(intersection))/(np.sum(union)+np.sum(intersection))\n return dice","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.523145Z","iopub.status.idle":"2023-11-24T07:02:37.523425Z","shell.execute_reply.started":"2023-11-24T07:02:37.523276Z","shell.execute_reply":"2023-11-24T07:02:37.523291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard(target, prediction):\n    intersection = np.logical_and(target, prediction)\n    union = np.logical_or(target, prediction)\n    iou_score = np.sum(intersection) / np.sum(union)\n    return iou_score","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.524204Z","iopub.status.idle":"2023-11-24T07:02:37.524509Z","shell.execute_reply.started":"2023-11-24T07:02:37.52434Z","shell.execute_reply":"2023-11-24T07:02:37.524364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def quick_plot(img, msk):\n    plt.figure(figsize=(10, 10))   \n    plt.subplot(1, 2, 1)\n    plt.axis('off')\n    plt.imshow(img)\n    plt.title('image')\n\n    plt.subplot(1, 2, 2)\n    plt.axis('off')\n    plt.imshow(msk)\n    plt.title('mask')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.525694Z","iopub.status.idle":"2023-11-24T07:02:37.525997Z","shell.execute_reply.started":"2023-11-24T07:02:37.525834Z","shell.execute_reply":"2023-11-24T07:02:37.525855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel = load_model('./unet_backbone_vgg19.h5') ","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.526854Z","iopub.status.idle":"2023-11-24T07:02:37.527131Z","shell.execute_reply.started":"2023-11-24T07:02:37.526982Z","shell.execute_reply":"2023-11-24T07:02:37.526996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Evaluating on DRIVE**","metadata":{}},{"cell_type":"code","source":"test_masks = np.concatenate([y for x, y in valid_dataset], axis=0)\nmasks = test_masks.ravel()","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.528301Z","iopub.status.idle":"2023-11-24T07:02:37.52862Z","shell.execute_reply.started":"2023-11-24T07:02:37.528433Z","shell.execute_reply":"2023-11-24T07:02:37.528448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs = np.concatenate([x for x, y in valid_dataset], axis=0)\npredictions = model.predict(test_imgs)\npredictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.529614Z","iopub.status.idle":"2023-11-24T07:02:37.529938Z","shell.execute_reply.started":"2023-11-24T07:02:37.52975Z","shell.execute_reply":"2023-11-24T07:02:37.529776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = predictions.ravel()\ny_pred = (y_pred > 0.5).astype('int32')\ny_pred","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.530885Z","iopub.status.idle":"2023-11-24T07:02:37.531192Z","shell.execute_reply.started":"2023-11-24T07:02:37.531019Z","shell.execute_reply":"2023-11-24T07:02:37.531042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(masks, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.532488Z","iopub.status.idle":"2023-11-24T07:02:37.532809Z","shell.execute_reply.started":"2023-11-24T07:02:37.532654Z","shell.execute_reply":"2023-11-24T07:02:37.532671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The Jaccard Score is: ', jaccard(y_pred, masks))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.53365Z","iopub.status.idle":"2023-11-24T07:02:37.533948Z","shell.execute_reply.started":"2023-11-24T07:02:37.533784Z","shell.execute_reply":"2023-11-24T07:02:37.533807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The Dice Score is: ', my_dice(y_pred, masks))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.535158Z","iopub.status.idle":"2023-11-24T07:02:37.535456Z","shell.execute_reply.started":"2023-11-24T07:02:37.535292Z","shell.execute_reply":"2023-11-24T07:02:37.535307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample Prediction","metadata":{}},{"cell_type":"code","source":"image = test_imgs[4]\nmask = test_masks[4]\nimage = np.expand_dims(image, axis=0)\npred_mask = model.predict(image)\npred_mask = (pred_mask > 0.5).astype('int32')\nplt.figure(figsize=(10,5))\nplt.subplot(121)\nplt.title('Original Mask')\nplt.imshow(mask, cmap='gray')\nplt.axis('off')\nplt.subplot(122)\nplt.title('Predicted Mask')\nplt.imshow(pred_mask[0], cmap='gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.536644Z","iopub.status.idle":"2023-11-24T07:02:37.536933Z","shell.execute_reply.started":"2023-11-24T07:02:37.536774Z","shell.execute_reply":"2023-11-24T07:02:37.536789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# HRF\n\n\nThe **HRF** dataset comes with retina image and corresponding vessel target and retina mask itself. See the code below.","metadata":{}},{"cell_type":"code","source":"hrf_dir = '../input/retinal-vessel-segmentation/HRF'\n\ninput_data = os.path.join(hrf_dir, 'images')\nimages = sorted(\n    [\n        os.path.join(input_data, fname)\n        for fname in os.listdir(input_data)\n        if fname.endswith(exts) and not fname.startswith(\".\")\n    ]\n)\n\n\ntarget_data = os.path.join(hrf_dir, 'mask')\nmasks1 = sorted(\n    [\n        os.path.join(target_data, fname)\n        for fname in os.listdir(target_data)\n        if fname.endswith(exts) and not fname.startswith(\".\")\n    ]\n)\n\ntarget_data = os.path.join(hrf_dir, 'manual1')\nmasks2 = sorted(\n    [\n        os.path.join(target_data, fname)\n        for fname in os.listdir(target_data)\n        if fname.endswith(exts) and not fname.startswith(\".\")\n    ]\n)\n\nlen(images), len(masks1), len(masks2)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.538222Z","iopub.status.idle":"2023-11-24T07:02:37.538503Z","shell.execute_reply.started":"2023-11-24T07:02:37.53835Z","shell.execute_reply":"2023-11-24T07:02:37.538365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def quick_plot(img, msk1, msk2):\n    plt.figure(figsize=(25, 25))   \n    plt.subplot(1, 3, 1)\n    plt.axis('off')\n    plt.imshow(img)\n    plt.title('image')\n\n    plt.subplot(1, 3, 2)\n    plt.axis('off')\n    plt.imshow(msk1)\n    plt.title('mask type 1')\n\n    plt.subplot(1, 3, 3)\n    plt.axis('off')\n    plt.imshow(msk2)\n    plt.title('mask type 2')\n    plt.show() \n\n\nfor img, msk1, msk2 in zip(images, masks1, masks2):\n    print(img[-9:],' | ', msk1[-14:], ' | ', msk2[-9:])\n    \n    # read files \n    read_img  = Image.open(img)\n    read_msk1 = Image.open(msk1)\n    read_msk2 = Image.open(msk2)\n    \n    # plot them \n    print(read_img.size, read_msk1.size, read_msk2.size)\n    quick_plot(read_img, read_msk1, read_msk2)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-24T07:02:37.539373Z","iopub.status.idle":"2023-11-24T07:02:37.539693Z","shell.execute_reply.started":"2023-11-24T07:02:37.5395Z","shell.execute_reply":"2023-11-24T07:02:37.539515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom PIL import Image\n\nprocessed_path = './Processed_images_HRF'\n\nos.mkdir(path=processed_path)\ndirectory = '../input/retinal-vessel-segmentation/HRF/images/'\nfor fname in os.listdir(directory):\n    image = plt.imread(directory + fname)\n    image = image[:,:,1]\n    processed_img = preprocess(image)\n    processed_img = Image.fromarray((processed_img * 255).astype(np.uint8))\n    processed_img.save(processed_path + '/' + fname)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.540572Z","iopub.status.idle":"2023-11-24T07:02:37.540872Z","shell.execute_reply.started":"2023-11-24T07:02:37.540711Z","shell.execute_reply":"2023-11-24T07:02:37.540733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data = os.path.join('./', 'Processed_images_HRF')\nimages = sorted(\n    [\n        os.path.join(input_data, fname)\n        for fname in os.listdir('./Processed_images_HRF')\n        if fname.endswith(exts) and not fname.startswith(\".\")\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.541922Z","iopub.status.idle":"2023-11-24T07:02:37.542207Z","shell.execute_reply.started":"2023-11-24T07:02:37.542054Z","shell.execute_reply":"2023-11-24T07:02:37.542068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 512\nBATCH_SIZE = 1\n\ndef read_files(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.io.decode_image(image) # out: (h, w, 4)\n    image = image[:,:,:3] # out: (h, w, 3)\n    image.set_shape([None, None, 3])\n    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n    image = image / 255.\n    return image\n\ndef load_data(image_list):\n    image = read_files(image_list)\n    return image\n\ndef data_generator(image_list):\n    dataset = tf.data.Dataset.from_tensor_slices((image_list))\n    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n    return dataset\n\ntest_dataset = data_generator(images)\ntest_dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.543264Z","iopub.status.idle":"2023-11-24T07:02:37.543593Z","shell.execute_reply.started":"2023-11-24T07:02:37.543394Z","shell.execute_reply":"2023-11-24T07:02:37.543418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 512\nBATCH_SIZE = 1\n\ndef read_files(mask_path):\n    mask = tf.io.read_file(mask_path)\n    mask = tfio.experimental.image.decode_tiff(mask) # out: (1, h, w, 3)\n    mask = mask[:,:,:3] # out: (h, w, 3)\n    mask = tf.image.rgb_to_grayscale(mask) # out: (h, w, 1)\n    mask = tf.divide(mask, 128)\n    mask.set_shape([None, None, 1])\n    mask = tf.image.resize(images=mask, size=[IMAGE_SIZE, IMAGE_SIZE])\n    mask = tf.cast(mask, tf.int32)\n    return mask\n\ndef load_data(mask_list):\n    mask = read_files(mask_list)\n    return mask\n\ndef data_generator(mask_list):\n    dataset = tf.data.Dataset.from_tensor_slices((mask_list))\n    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n    return dataset\n\nmask_dataset = data_generator(masks2)\nmask_dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.544956Z","iopub.status.idle":"2023-11-24T07:02:37.545273Z","shell.execute_reply.started":"2023-11-24T07:02:37.545099Z","shell.execute_reply":"2023-11-24T07:02:37.545124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_dataset)\npredictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.546141Z","iopub.status.idle":"2023-11-24T07:02:37.546443Z","shell.execute_reply.started":"2023-11-24T07:02:37.546273Z","shell.execute_reply":"2023-11-24T07:02:37.546297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = predictions.ravel()\ny_pred = (y_pred > 0.5).astype('int32')\ny_pred","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.547254Z","iopub.status.idle":"2023-11-24T07:02:37.547597Z","shell.execute_reply.started":"2023-11-24T07:02:37.547396Z","shell.execute_reply":"2023-11-24T07:02:37.547417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"masks = mask_dataset.unbatch()\nmasks = list(masks.as_numpy_iterator())\ntest_masks = np.array(masks)\nmasks = test_masks.ravel()\nmasks","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.548853Z","iopub.status.idle":"2023-11-24T07:02:37.549138Z","shell.execute_reply.started":"2023-11-24T07:02:37.548986Z","shell.execute_reply":"2023-11-24T07:02:37.549001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jaccard_score = jaccard(y_pred, masks)\ndice = my_dice(y_pred, masks)\n\nprint('The Jaccard Score is: ', jaccard_score)\nprint('The Dice Score is: ', dice)\nprint(classification_report(masks, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.550443Z","iopub.status.idle":"2023-11-24T07:02:37.550888Z","shell.execute_reply.started":"2023-11-24T07:02:37.550662Z","shell.execute_reply":"2023-11-24T07:02:37.550686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Sample Prediction","metadata":{}},{"cell_type":"code","source":"test_imgs = np.concatenate([x for x in test_dataset], axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.556645Z","iopub.status.idle":"2023-11-24T07:02:37.55697Z","shell.execute_reply.started":"2023-11-24T07:02:37.556794Z","shell.execute_reply":"2023-11-24T07:02:37.556822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = test_imgs[21]\nmask = test_masks[21]\nimage = np.expand_dims(image, axis=0)\npred_mask = model.predict(image)\npred_mask = (pred_mask > 0.5).astype('int32')\nplt.figure(figsize=(10,5))\nplt.subplot(121)\nplt.title('Original Mask')\nplt.imshow(mask, cmap='gray')\nplt.axis('off')\nplt.subplot(122)\nplt.title('Predicted Mask')\nplt.imshow(pred_mask[0], cmap='gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.558218Z","iopub.status.idle":"2023-11-24T07:02:37.558836Z","shell.execute_reply.started":"2023-11-24T07:02:37.558615Z","shell.execute_reply":"2023-11-24T07:02:37.558646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CHASE DB1\n\nThis data set comes with both retina image and corresponding target mask. Note that, for each retina image, there are two mask. Below, in data loading time, we only pick one mask agains the retina image. ","metadata":{}},{"cell_type":"code","source":"hrf_dir = '../input/retinal-vessel-segmentation/CHASE_DB1'\n\n\ninput_data = os.path.join(hrf_dir, 'Images')\nimages = sorted(\n    [\n        os.path.join(input_data, fname)\n        for fname in os.listdir(input_data)\n        if fname.endswith(exts) and not fname.startswith(\".\")\n    ]\n)\n\n\ntarget_data = os.path.join(hrf_dir, 'Masks')\nmasks = sorted(\n    [\n        os.path.join(target_data, fname)\n        for fname in os.listdir(target_data)\n        if fname.endswith('_2ndHO.png') and not fname.startswith(\".\") # _2ndHO.png, _1stHO.png\n    ]\n)\n\n\nlen(images), len(masks)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.559826Z","iopub.status.idle":"2023-11-24T07:02:37.560116Z","shell.execute_reply.started":"2023-11-24T07:02:37.559958Z","shell.execute_reply":"2023-11-24T07:02:37.559973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"code","source":"import cv2\nfrom PIL import Image\n\nprocessed_path = './Processed_images_ChaseDB1'\n\nos.mkdir(path=processed_path)\ndirectory = '../input/retinal-vessel-segmentation/CHASE_DB1/Images/'\nfor fname in os.listdir(directory):\n    image = plt.imread(directory + fname)\n    image = image[:,:,1]\n    processed_img = preprocess(image)\n    processed_img = Image.fromarray((processed_img * 255).astype(np.uint8))\n    processed_img.save(processed_path + '/' + fname)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.561437Z","iopub.status.idle":"2023-11-24T07:02:37.561777Z","shell.execute_reply.started":"2023-11-24T07:02:37.561606Z","shell.execute_reply":"2023-11-24T07:02:37.56163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_data = os.path.join('./', 'Processed_images_ChaseDB1')\nimages = sorted(\n    [\n        os.path.join(input_data, fname)\n        for fname in os.listdir('./Processed_images_ChaseDB1')\n        if fname.endswith(exts) and not fname.startswith(\".\")\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.563191Z","iopub.status.idle":"2023-11-24T07:02:37.56347Z","shell.execute_reply.started":"2023-11-24T07:02:37.563322Z","shell.execute_reply":"2023-11-24T07:02:37.563337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 512\nBATCH_SIZE = 1\n\ndef read_files(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.io.decode_image(image) # out: (h, w, 4)\n    image = image[:,:,:3] # out: (h, w, 3)\n    image.set_shape([None, None, 3])\n    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n    image = image / 255.\n    return image\n\ndef load_data(image_list):\n    image = read_files(image_list)\n    return image\n\ndef data_generator(image_list):\n    dataset = tf.data.Dataset.from_tensor_slices((image_list))\n    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n    return dataset\n\ntest_dataset = data_generator(images)\ntest_dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.564324Z","iopub.status.idle":"2023-11-24T07:02:37.564658Z","shell.execute_reply.started":"2023-11-24T07:02:37.564457Z","shell.execute_reply":"2023-11-24T07:02:37.564481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = 512\nBATCH_SIZE = 1\n\ndef read_files(mask_path):\n    mask = tf.io.read_file(mask_path)\n    mask = tf.io.decode_gif(mask) # out: (1, h, w, 3)\n    mask = tf.squeeze(mask) # out: (h, w, 3)\n    mask = tf.image.rgb_to_grayscale(mask) # out: (h, w, 1)\n    mask = tf.divide(mask, 128)\n    mask.set_shape([None, None, 1])\n    mask = tf.image.resize(images=mask, size=[IMAGE_SIZE, IMAGE_SIZE])\n    mask = tf.cast(mask, tf.int32)\n    return mask\n\ndef load_data(mask_list):\n    mask = read_files(mask_list)\n    return mask\n\ndef data_generator(mask_list):\n    dataset = tf.data.Dataset.from_tensor_slices((mask_list))\n    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)\n    return dataset\n\nmask_dataset = data_generator(masks)\nmask_dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.56573Z","iopub.status.idle":"2023-11-24T07:02:37.566144Z","shell.execute_reply.started":"2023-11-24T07:02:37.565919Z","shell.execute_reply":"2023-11-24T07:02:37.565942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test_dataset)\npredictions.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.567136Z","iopub.status.idle":"2023-11-24T07:02:37.567612Z","shell.execute_reply.started":"2023-11-24T07:02:37.567342Z","shell.execute_reply":"2023-11-24T07:02:37.567367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"masks = mask_dataset.unbatch()\nmasks = list(masks.as_numpy_iterator())\ntest_masks = np.array(masks)\nmasks = test_masks.ravel()\nmasks","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.569115Z","iopub.status.idle":"2023-11-24T07:02:37.569553Z","shell.execute_reply.started":"2023-11-24T07:02:37.569299Z","shell.execute_reply":"2023-11-24T07:02:37.569321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = predictions.ravel()\ny_pred = (y_pred > 0.5).astype('int32')\ny_pred","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.570906Z","iopub.status.idle":"2023-11-24T07:02:37.571319Z","shell.execute_reply.started":"2023-11-24T07:02:37.571088Z","shell.execute_reply":"2023-11-24T07:02:37.57111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(classification_report(masks, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.572228Z","iopub.status.idle":"2023-11-24T07:02:37.57266Z","shell.execute_reply.started":"2023-11-24T07:02:37.572406Z","shell.execute_reply":"2023-11-24T07:02:37.572428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jaccard_score = jaccard(y_pred, masks)\nprint('The Jaccard Score is: ', jaccard_score)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.573907Z","iopub.status.idle":"2023-11-24T07:02:37.574309Z","shell.execute_reply.started":"2023-11-24T07:02:37.574087Z","shell.execute_reply":"2023-11-24T07:02:37.574109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dice = my_dice(y_pred, masks)\n# quick_plot(mask, pred_mask)\n    \nprint('The Dice Score is: ', dice)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.575356Z","iopub.status.idle":"2023-11-24T07:02:37.575787Z","shell.execute_reply.started":"2023-11-24T07:02:37.575557Z","shell.execute_reply":"2023-11-24T07:02:37.575581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_imgs = np.concatenate([x for x in test_dataset], axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.576979Z","iopub.status.idle":"2023-11-24T07:02:37.577261Z","shell.execute_reply.started":"2023-11-24T07:02:37.577112Z","shell.execute_reply":"2023-11-24T07:02:37.577127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = test_imgs[20]\nmask = test_masks[20]\nimage = np.expand_dims(image, axis=0)\npred_mask = model.predict(image)\npred_mask = (pred_mask > 0.5).astype('int32')\nplt.figure(figsize=(10,5))\nplt.subplot(121)\nplt.title('Original Mask')\nplt.imshow(mask, cmap='gray')\nplt.axis('off')\nplt.subplot(122)\nplt.title('Predicted Mask')\nplt.imshow(pred_mask[0], cmap='gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.578256Z","iopub.status.idle":"2023-11-24T07:02:37.578581Z","shell.execute_reply.started":"2023-11-24T07:02:37.578387Z","shell.execute_reply":"2023-11-24T07:02:37.57841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Our High Quality Image Dataset","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 512\n\norg_image = plt.imread('/kaggle/input/neu-2dsegmentation/segmentation/test/image/1.jpg')\nimage = org_image[:,:,1]\nprocessed_img = preprocess(image)\n# processed_img = Image.fromarray((processed_img * 255).astype(np.uint8))\nprocessed_img = (processed_img * 255).astype(np.uint8)\nimage = tf.convert_to_tensor(processed_img)\nimage.set_shape([None, None, 3])\nimage = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\nimage = image / 255.\nimage = np.expand_dims(image, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.579496Z","iopub.status.idle":"2023-11-24T07:02:37.579825Z","shell.execute_reply.started":"2023-11-24T07:02:37.579661Z","shell.execute_reply":"2023-11-24T07:02:37.579683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_mask = model.predict(image)\npred_mask = (pred_mask > 0.5).astype('int32')\nplt.figure(figsize=(15,8))\nplt.subplot(131)\nplt.title('Original Image')\nplt.imshow(org_image)\nplt.axis('off')\nplt.subplot(132)\nplt.title('Processed Image')\nplt.imshow(image[0], cmap='gray')\nplt.axis('off')\nplt.subplot(133)\nplt.title('Predicted Mask')\nplt.imshow(pred_mask[0], cmap='gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.581027Z","iopub.status.idle":"2023-11-24T07:02:37.581325Z","shell.execute_reply.started":"2023-11-24T07:02:37.581163Z","shell.execute_reply":"2023-11-24T07:02:37.581184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef save_predicted_mask(org_image_path, model, output_path, IMAGE_SIZE=512):\n    # Load the original image\n    org_image = plt.imread(org_image_path)\n    \n    # Preprocess the image\n    image = org_image[:, :, 1]\n    processed_img = preprocess(image)\n    processed_img = (processed_img * 255).astype(np.uint8)\n    image = tf.convert_to_tensor(processed_img)\n    image.set_shape([None, None, 3])\n    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n    image = image / 255.\n    image = np.expand_dims(image, axis=0)\n\n    # Predict the mask\n    pred_mask = model.predict(image)\n    pred_mask = (pred_mask > 0.5).astype('int32')\n    pred_mask = pred_mask[0][:, :, 0]\n\n    # Create a subplot to display the original and predicted images\n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n\n    # Display the original image\n    axes[0].imshow(org_image)\n    axes[0].set_title('Original Image')\n\n    # Display the predicted mask\n    axes[1].imshow(pred_mask, cmap='gray')\n    axes[1].set_title('Predicted Mask')\n\n    # Save the predicted mask with a suffix\n    save_dir = os.path.dirname(output_path)\n    os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n    base_name = os.path.splitext(os.path.basename(output_path))[0]\n\n    pred_save_path = os.path.join(save_dir, f'{base_name}.png')\n    plt.imsave(pred_save_path, pred_mask, cmap='gray')\n\n    # Close the figure to free up resources\n    plt.close(fig)\n\n# Example usage:\nfor i in range(1, 21): \n    org_image_path = f'/kaggle/input/neu-2dsegmentation/segmentation/test/image/{i}.jpg'\n    save_image_path = f'/kaggle/working/answer3/{i}.png'\n    save_predicted_mask(org_image_path, model, save_image_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:46:23.584783Z","iopub.execute_input":"2023-11-24T07:46:23.585394Z","iopub.status.idle":"2023-11-24T07:46:27.071793Z","shell.execute_reply.started":"2023-11-24T07:46:23.585357Z","shell.execute_reply":"2023-11-24T07:46:27.0711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\ndef create_zip(source_folder, output_path):\n    shutil.make_archive(output_path, 'zip', source_folder)\n\n# 指定目标文件夹和压缩文件路径\nsource_directory = '/kaggle/working/answer3'\nzip_file_path = '/kaggle/working/answer3'\n\n# 调用函数进行压缩\ncreate_zip(source_directory, zip_file_path)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:47:13.83265Z","iopub.execute_input":"2023-11-24T07:47:13.833183Z","iopub.status.idle":"2023-11-24T07:47:13.849143Z","shell.execute_reply.started":"2023-11-24T07:47:13.833142Z","shell.execute_reply":"2023-11-24T07:47:13.848404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Our Low Quality Image Dataset","metadata":{}},{"cell_type":"code","source":"IMAGE_SIZE = 512\n\norg_image = plt.imread('../input/our-retinal-fundus-image-dataset/HHFC Images/HHFC Images/EL 180624436112213.jpg')\nimage = org_image[:,:,1]\nprocessed_img = preprocess(image)\n# processed_img = Image.fromarray((processed_img * 255).astype(np.uint8))\nprocessed_img = (processed_img * 255).astype(np.uint8)\nimage = tf.convert_to_tensor(processed_img)\nimage.set_shape([None, None, 3])\nimage = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\nimage = image / 255.\nimage = np.expand_dims(image, axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.583865Z","iopub.status.idle":"2023-11-24T07:02:37.584144Z","shell.execute_reply.started":"2023-11-24T07:02:37.583995Z","shell.execute_reply":"2023-11-24T07:02:37.58401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_mask = model.predict(image)\npred_mask = (pred_mask > 0.5).astype('int32')\nplt.figure(figsize=(15,8))\nplt.subplot(131)\nplt.title('Original Image')\nplt.imshow(org_image)\nplt.axis('off')\nplt.subplot(132)\nplt.title('Processed Image')\nplt.imshow(image[0], cmap='gray')\nplt.axis('off')\nplt.subplot(133)\nplt.title('Predicted Mask')\nplt.imshow(pred_mask[0], cmap='gray')\nplt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2023-11-24T07:02:37.585146Z","iopub.status.idle":"2023-11-24T07:02:37.585454Z","shell.execute_reply.started":"2023-11-24T07:02:37.585283Z","shell.execute_reply":"2023-11-24T07:02:37.585299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href='./unet_backbone_vgg19.h5'>Download VGG19 Model</a>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}